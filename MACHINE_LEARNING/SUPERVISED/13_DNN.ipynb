{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f6af3c",
   "metadata": {},
   "source": [
    "# ğŸŒŸ **DNN Algorithm (Deep Neural Network)** ğŸ¤–ğŸ§ \n",
    "\n",
    "## ğŸ“Œ **Short Definition (Simple Words)**\n",
    "\n",
    "A **Deep Neural Network (DNN)** is a type of **artificial intelligence** ğŸ¤– that mimics how the human brain ğŸ§  works. Itâ€™s made of **layers of neurons** that help computers **learn patterns from data**, like recognizing faces, predicting stock prices, or recommending movies ğŸ¬.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ğŸ§± **Structure of a DNN**\n",
    "\n",
    "DNNs are made up of **layers**:\n",
    "\n",
    "1. ğŸ”¹ **Input Layer** â€“ Takes raw data (like numbers, images, or text).\n",
    "2. ğŸ”¸ **Hidden Layers** â€“ Multiple layers that process the data step by step.\n",
    "3. ğŸ”¹ **Output Layer** â€“ Gives the final result (like \"spam\" or \"not spam\").\n",
    "\n",
    "> Each layer is made of tiny units called **neurons**, and they are connected just like brain cells ğŸ§ ğŸ”—.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  **How It Works (Simplified)**\n",
    "\n",
    "1. ğŸ“¥ Input data goes into the network.\n",
    "2. â• Each neuron calculates a **weighted sum** + a **bias**.\n",
    "3. ğŸŒ€ It passes through an **activation function** (like ReLU, Sigmoid) to decide what to pass forward.\n",
    "4. ğŸ” This continues through all hidden layers.\n",
    "5. ğŸ“¤ Final layer gives the output.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“š **Key Concepts to Know**\n",
    "\n",
    "| ğŸ·ï¸ Concept                | ğŸ” Description                                          |\n",
    "| -------------------------- | ------------------------------------------------------- |\n",
    "| ğŸ¯ **Epoch**               | One full pass of the entire dataset through the DNN.    |\n",
    "| ğŸ§® **Weights & Bias**      | Parameters the model learns to make better predictions. |\n",
    "| ğŸ§ª **Activation Function** | Adds non-linearity (e.g., ReLU, Sigmoid, Tanh).         |\n",
    "| ğŸ§  **Backpropagation**     | Method to update weights using the error.               |\n",
    "| ğŸ“ **Training**            | Process of learning patterns from data.                 |\n",
    "| ğŸ“Š **Loss Function**       | Tells how far the prediction is from the actual result. |\n",
    "| ğŸ› ï¸ **Optimizer**          | Algorithm (like SGD, Adam) that adjusts weights.        |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸš€ **Where DNNs Are Used**\n",
    "\n",
    "ğŸ” Image recognition\n",
    "\n",
    "ğŸ’¬ Natural language processing (NLP)\n",
    "\n",
    "ğŸ® Game AI\n",
    "\n",
    "ğŸ§¬ Healthcare diagnosis\n",
    "\n",
    "ğŸ›ï¸ Recommendation systems\n",
    "\n",
    "ğŸ“ˆ Stock market predictions\n",
    "\n",
    "\n",
    "\n",
    "## âœ… **Pros**\n",
    "\n",
    "âœ”ï¸ Learns complex patterns\n",
    "\n",
    "âœ”ï¸ Works well on big data\n",
    "\n",
    "âœ”ï¸ Highly flexible and powerful\n",
    "\n",
    "## âŒ **Cons**\n",
    "\n",
    "â— Needs a lot of data\n",
    "\n",
    "â— Computationally expensive\n",
    "\n",
    "â— Takes time to train\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ“˜ **Extra Tips for Beginners**\n",
    "\n",
    "* Start with **basic neural networks** before going deep.\n",
    "* Use tools like **TensorFlow** or **Keras** for building DNNs.\n",
    "* Practice with datasets from **Kaggle** or **UCI ML Repository**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fb879",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Great question! ğŸ˜Š Yes, a **DNN (Deep Neural Network)** is **very similar to an FNN (Feedforward Neural Network)** â€” in fact, you can think of a **DNN as just a \"deeper\" version of an FNN**. Letâ€™s break it down for you in a stylish way! ğŸŒˆâœ¨\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ¤– **DNN vs FNN â€“ Whatâ€™s the Difference?** ğŸ§ âš¡\n",
    "\n",
    "| ğŸ” Feature                  | ğŸ§± FNN (Feedforward Neural Network)            | ğŸ§  DNN (Deep Neural Network)             |\n",
    "| --------------------------- | ---------------------------------------------- | ---------------------------------------- |\n",
    "| ğŸ’¡ **Basic Idea**           | A neural network where data flows only forward | A deeper FNN with **many hidden layers** |\n",
    "| ğŸ”„ **Flow of Data**         | One direction only â†’                           | Same: forward only â†’                     |\n",
    "| ğŸ§± **No. of Hidden Layers** | Usually **1 or 2 layers**                      | **More than 2** (can be 10s or 100s!)    |\n",
    "| ğŸ§  **Complexity**           | Simpler, used for basic tasks                  | More complex, handles **advanced tasks** |\n",
    "| ğŸ§ª **Use Case Examples**    | Basic classification or regression             | Image recognition, NLP, speech, etc.     |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  In Simple Words:\n",
    "\n",
    "ğŸ‘‰ **Every DNN is an FNN**, but not every FNN is deep enough to be called a DNN.\n",
    "\n",
    "\n",
    "- If a neural network has **many hidden layers**, itâ€™s called a **Deep Neural Network (DNN)**.\n",
    "- If it has **just a few (1-2) hidden layers**, itâ€™s usually just called an **FNN**.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸŒŸ Analogy Time:\n",
    "\n",
    "Think of it like a **cake** ğŸ‚:\n",
    "\n",
    "* ğŸ° **FNN** = a small cake with 2 layers\n",
    "* ğŸ‚ **DNN** = a tall cake with 10+ layers\n",
    "  Both are cakes (neural networks), but DNN is just **\"taller\" and more powerful**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5293a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c921b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed16f33",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ğŸ§© `import tensorflow as tf`\n",
    "\n",
    "ğŸ”¹ **TensorFlow** is a powerful library for building and training machine learning models.\n",
    "\n",
    "ğŸ”¹ We call it `tf` to keep it short in code.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§  `from tensorflow.keras.models import Sequential`\n",
    "\n",
    "ğŸ”¹ **Sequential** is a way to build a model **step-by-step, layer-by-layer**.\n",
    "\n",
    "ğŸ”¹ Use it when your model goes straight from input â†’ hidden â†’ output (no branches or loops).\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ§± `from tensorflow.keras.layers import Dense, Flatten`\n",
    "\n",
    "ğŸ”¹ **Dense**: Fully connected layer â€“ each neuron connects to **every neuron** in the next layer.\n",
    "\n",
    "ğŸ”¹ **Flatten**: Turns 2D input (like an image) into 1D â€“ prepares data for the Dense layers.\n",
    "\n",
    "\n",
    "### ğŸ—ƒï¸ `from tensorflow.keras.datasets import mnist`\n",
    "\n",
    "ğŸ”¹ Loads the **MNIST dataset** â€“ 70,000 images of handwritten digits (0â€“9).\n",
    "\n",
    "ğŸ”¹ Already split into **training and testing** sets.\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ¯ `from tensorflow.keras.utils import to_categorical`\n",
    "\n",
    "ğŸ”¹ Converts labels like `5` into a **one-hot encoded vector** like `[0 0 0 0 0 1 0 0 0 0]`.\n",
    "\n",
    "ğŸ”¹ Needed for classification problems where you have multiple classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868ff4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data (images of digits 0â€“9)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55963a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and One-hot encode\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d803b3",
   "metadata": {},
   "source": [
    "### ğŸ§±  Feedforward Neural Network (FNN) â€“ Shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# FNN with 1 hidden layer\n",
    "fnn_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),     # Input Layer\n",
    "    Dense(64, activation='relu'),      # Hidden Layer (shallow)\n",
    "    Dense(10, activation='softmax')    # Output Layer (10 classes)\n",
    "])\n",
    "\n",
    "fnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "fnn_model.summary()  # Print model summary\n",
    "fnn_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd79224",
   "metadata": {},
   "source": [
    "### ğŸ§   Deep Neural Network (DNN) â€“ Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abd117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nagesh Agrawal\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m100,480\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m330\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.4667 - val_accuracy: 0.9637 - val_loss: 0.1195\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9661 - loss: 0.1120 - val_accuracy: 0.9688 - val_loss: 0.0972\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0750 - val_accuracy: 0.9701 - val_loss: 0.0928\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0582 - val_accuracy: 0.9724 - val_loss: 0.0887\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0447 - val_accuracy: 0.9758 - val_loss: 0.0809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22424bbe960>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN with multiple hidden layers\n",
    "dnn_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),       # Input Layer\n",
    "    Dense(128, activation='relu'),       # Hidden Layer 1\n",
    "    Dense(64, activation='relu'),        # Hidden Layer 2\n",
    "    Dense(32, activation='relu'),        # Hidden Layer 3\n",
    "    Dense(10, activation='softmax')      # Output Layer\n",
    "])\n",
    "\n",
    "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.summary()  # Print model summary\n",
    "dnn_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c13248",
   "metadata": {},
   "source": [
    "## ğŸ“Š **Summary**\n",
    "\n",
    "| Model | Hidden Layers | Training Time | Performance |\n",
    "| ----- | ------------- | ------------- | ----------- |\n",
    "| FNN   | 1             | Fast â±ï¸       | Good ğŸ‘     |\n",
    "| DNN   | 3+            | Slower ğŸ¢     | Better ğŸ’ª   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877a7d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059322a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
